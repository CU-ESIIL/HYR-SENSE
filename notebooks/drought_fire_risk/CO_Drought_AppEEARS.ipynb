{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece25488-6650-4b31-822e-52a2088ea615",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How to work with AρρEEARS Cloud Optimized GeoTIFF (COG) outputs\n",
    "\n",
    "## Summary  \n",
    "\n",
    "This tutorial demonstrates how to access AρρEEARS Cloud Optimized GeoTIFF (COG) outputs in AWS. NASA's Application for Extracting and Exploring Analysis Ready Samples ([AρρEEARS](https://appeears.earthdatacloud.nasa.gov/)) is deployed in NASA's Earthdata Cloud space located in **AWS us-west 2**. This enables the user working from cloud instances deployed in **AWS us-west 2** to access outputs directly from an AWS S3 bucket. In this tutorial, we will walk through the process of submitting an area sample and accessing a Cloud Optimized GeoTIFF (COG) outputs from AppEEARS.\n",
    "\n",
    "This tutorial highlights the Dixie Fire, the second-largest fire in California history. According to [CalFire](https://www.fire.ca.gov/incidents/2021/7/13/dixie-fire/), the fire has started on July 13, 2021 and burned more than 963,276 acres. On August 18, the Dixie Fire merged with the Morgan Fire, which had been started by lightning August 12, close to Lassen National Park. The fire was one hundred percent contained by October 2021.    \n",
    "\n",
    "## Requirements  \n",
    "\n",
    "- Earthdata Login Authentication is required to uses the AρρEEARS API and to access AρρEEARS outputs directly.  \n",
    "\n",
    "## Learning Objectives  \n",
    "\n",
    "- Learn how to access AρρEEARS Cloud Optimized GeoTIFF (COG) outputs\n",
    "\n",
    "\n",
    "## Tutorial Outline \n",
    "\n",
    "1. Setting Up  \n",
    "2. Submit an area request in AppEEARS  \n",
    "3. Extract the Direct S3 links  \n",
    "4. Create a boto3 Refreshable Session  \n",
    "5. Single COG File In-Region Direct S3 Access   \n",
    "6. Multiple COG File In-Region Direct S3 Access  \n",
    "7. Explore the EVI Time Series   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d91645-8236-4031-8fb1-7d71ea0f9f8b",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3042e1-6301-4ce4-906b-fa70296f99cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed631cf3-bc44-4039-98c3-01c56ec544ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import earthaccess\n",
    "import getpass, pprint, time, os, cgi, json\n",
    "import geopandas \n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "from netrc import netrc\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import rioxarray\n",
    "import xarray\n",
    "import hvplot.xarray\n",
    "import holoviews\n",
    "import geoviews\n",
    "import rasterio \n",
    "from rasterio.plot import show\n",
    "import pandas\n",
    "import warnings\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import folium\n",
    "from folium import plugins\n",
    "import branca.colormap as cm\n",
    "from matplotlib import colors as colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2679e1-a79f-4edb-ac71-7a53c3aac62e",
   "metadata": {},
   "source": [
    "To successfully run this tutorial, it is required to create a **.netrc** file in your home directory. The function `_validate_netrc` defined in `aws_session` checks if a properly formatted netrc file exists in your home directory. If the netrc file does not exist, it will prompt you for your Earthdata Login username and password and will create a netrc file. Please see the **Prerequisites** section in [**README.md**](../README.md). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ebdb9-a563-4d7d-8053-158193cec4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00a547-3f0f-407d-b7c0-14ceb0a43187",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = geopandas.read_file('../../data/co_agriculture.geojson')\n",
    "roi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db277b20",
   "metadata": {},
   "source": [
    "Get the center coordinates from the input geojson. This is used later when plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022b1cd-353c-478e-8171-851c894bc26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_center = roi.centroid.x\n",
    "y_center = roi.centroid.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24072e6b-6deb-4e2e-aaca-29422e79aae2",
   "metadata": {},
   "source": [
    "## 2. Submit an area request in AρρEEARS  \n",
    "In this step, we are going to submit an area request with GeoTIFF as an output format. You can also submit this request using [AρρEEARS Graphic User Interface (GUI)](https://appeears.earthdatacloud.nasa.gov/task/area) and upload the JSON file provided in the repository (AppEEARS-Data-Resources/Data/Dixie-Fire-request.json). If you have your completed request, save your `task_id` to a variable, skip this step, and move to the next step of tutorial.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f61879-a31f-4910-b933-d49aae55aac6",
   "metadata": {},
   "source": [
    "Assign the AρρEEARS API endpoint to a variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0fe62-090a-4a4e-bd9b-a76324df9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "appeears_API_endpoint = 'https://appeears.earthdatacloud.nasa.gov/api/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a06334-fd80-43c9-8060-658039193773",
   "metadata": {},
   "source": [
    "A **Bearer Token** is needed to submit requests to the AρρEEARS API. To generated a token, a `POST` request containing Earthdata Login credentials stored in the **.netrc** file is submitted to the [`login`](https://appeears.earthdatacloud.nasa.gov/api/#authentication) service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a3399-0dba-4177-a536-d5379445a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "login_req = requests.post(f'{appeears_API_endpoint}login', auth = (auth.username,auth.password))\n",
    "login_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7edbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = login_req.json()['token']                      # Save login token to a variable\n",
    "head = {'Authorization': 'Bearer {}'.format(token)}    # Create a header to store token information, needed to submit a request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe9aa0-7b75-4c11-acd2-aacf975b2dd2",
   "metadata": {},
   "source": [
    "Next, compile a JSON object with the request parameters. The Dixie fire started on July 13, 2021, however we're going to extended the search query to include two years to see the time series. A GeoJSON of Region of Interest(ROI) including Lassen National Park region, CA can be downloaded from the repository. For this tutorial, we are requesting the `_500m_16_days_EVI` layer from `MOD13A1.061` to see how Enhanced Vegetation Indices (EVI) varies before and after the fire event. Learn more about the MODIS Vegetation Indices 16-Day Version 6.1 product [here](https://doi.org/10.5067/MODIS/MOD13A1.061). Below we define the AρρEEARS search parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590830e-cac1-41ce-a5bd-e3f076135344",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_req = requests.get(f'{appeears_API_endpoint}product').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069bdfb1-588f-4b59-b310-25470fcddf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_eco = [x for x in product_req if 'ECOSTRESS' in x['Platform']]    # Get ECOSTRESS product information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f954b2-aaf1-4560-8bf7-9353a4189fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_req = requests.get(f'{appeears_API_endpoint}product/ECO4ESIALEXI.001').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b0ac47-aeee-4805-8ee6-2476d269cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_req.keys()    # These are the layer names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf1a47e-6aef-4bc4-9819-77ec5419c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"Colorado_Drought\"\n",
    "task_type = 'area'                  # Type of task, area or point\n",
    "proj = 'geographic'                 # Set output projection \n",
    "outFormat = 'geotiff'               # Set output file format type\n",
    "startDate = '06-01'            # Start of the date range for which to extract data: MM-DD-YYYY\n",
    "endDate = '06-30'              # End of the date range for which to extract data: MM-DD-YYYY\n",
    "yearRange = [2020,2021]\n",
    "ROI =  roi.to_json()\n",
    "prodLayer = [{'layer': 'EVAPORATIVE_STRESS_INDEX_ALEXI_ESIdaily', 'product': 'ECO4ESIALEXI.001'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3df3d-63d2-43f0-a636-4ee5a26f39c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = {\n",
    "    'task_type': task_type,\n",
    "    'task_name': task_name,\n",
    "    'params': {\n",
    "         'dates': [\n",
    "         {\n",
    "             'startDate': startDate,\n",
    "             'endDate': endDate,\n",
    "             'recurring': True,\n",
    "             'yearRange': yearRange\n",
    "         }],\n",
    "         'layers': prodLayer,\n",
    "         'output': {\n",
    "                 'format': {\n",
    "                         'type': outFormat}, \n",
    "                         'projection': proj},\n",
    "         'geo': json.loads(ROI),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc394d-fcf8-4c0f-9e5e-2779c1c824e8",
   "metadata": {},
   "source": [
    "Next, submit the AρρEEARS request using `post` function from `requests` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b170a-cb72-48bc-af7d-bc4d4384ef17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_response = requests.post(f'{appeears_API_endpoint}task', json=task, headers=head).json()    # Post json to the API task service, return response as json\n",
    "task_response                                                                                    # Print task response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27257746-54c5-491c-b044-ec867e8715d9",
   "metadata": {},
   "source": [
    "The `task_id` will be needed to get status information about the request and to later find the AρρEEARS outputs for the request. We will save the `task_id` to a variable and wait until our request is processed and complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88557fdc-cb11-4cf1-b10c-606f4e2b0a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_id = task_response['task_id']\n",
    "task_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0e4ca-d45f-4165-b61c-32f5812f39ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ping API until request is complete, then continue to Section 3\n",
    "while requests.get(f'{appeears_API_endpoint}task/{task_id}', headers=head).json()['status'] != 'done':\n",
    "    print(requests.get(f'{appeears_API_endpoint}task/{task_id}', headers=head).json()['status'])\n",
    "    time.sleep(60)\n",
    "print(requests.get(f'{appeears_API_endpoint}task/{task_id}', headers=head).json()['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a553ad8-ae30-4bb8-bd16-189cff4f97c7",
   "metadata": {},
   "source": [
    "## 3. Access Request Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002a29a-1183-4863-ade7-7f9c7b1dc1b4",
   "metadata": {},
   "source": [
    "Once our outputs are ready, we can get the bundle information for the files included in the outputs. If you submitted your request using AρρEEARS GUI, assign your sample's `task_id` to the variable `task_id` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f5cd6a-f31e-497e-9e45-b8db71309164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task_id = 'fdd28cde-de2b-40b4-b3f9-edf33f585649'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd89a2-a979-4ba1-992f-2315c4454ae1",
   "metadata": {},
   "source": [
    "`requests.get` is used to get information about our bundle. The bundle information includes `s3_url` in addition to the other information such as output `file_name`, `file_id`, and `file_type`.  \n",
    "\n",
    "Each output file can be downloaded using the `file_id` (see section 4 in [AppEEARS_API_Area.ipynb](AppEEARS_API_Area.ipynb). Since AρρEEARS outputs are stored in an S3 bucket, outputs can also be accessed using `S3_url` if you are working from an cloud instance in **AWS us-west-2**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e178306-3e7d-4bd1-a6fc-e59932ab1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = requests.get(f'{appeears_API_endpoint}bundle/{task_id}', headers=head).json()  # Call API and return bundle contents for the task_id as json\n",
    "#bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53db0c4-920b-425e-970b-0a1067173b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {x['file_id']:x['file_name'] for x in bundle['files'] if 'ESIdaily' in x['file_name'] and '.tif' in x['file_name']}\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af0e2ee-85c7-41c3-a4fc-0109e075ee01",
   "metadata": {},
   "source": [
    "Download files to data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25e6be-2fe3-46a3-8055-05bdd15eb9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fd6bbc-52fd-46bb-aae9-d9eaf02f17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    dl = requests.get(f'{appeears_API_endpoint}bundle/{task_id}/{f}', headers=head, stream=True, allow_redirects = 'True')    # Get a stream to the bundle file\n",
    "    if files[f].endswith('.tif'):\n",
    "        filename = files[f].split('/')[1]\n",
    "    else:\n",
    "        filename = files[f] \n",
    "    filepath = os.path.join('data', filename)                          # Create output file path\n",
    "    with open(filepath, 'wb') as f:                                    # Write file to dest dir\n",
    "        for data in dl.iter_content(chunk_size=8192): f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7c8ee-ae99-4ede-b476-3daced5eb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_2020 = [x for x in os.listdir('data') if 'ECO4ESIALEXI' in x and 'doy2020' in x]\n",
    "file_list_2020.sort()\n",
    "file_list_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95501699-6968-40d2-a67d-281ed8ddca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_2021 = [x for x in os.listdir('data') if 'ECO4ESIALEXI' in x and 'doy2021' in x]\n",
    "file_list_2021.sort()\n",
    "file_list_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0661e-c8b9-445a-8e5b-212487ac01f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "match_list = []\n",
    "\n",
    "for file1 in file_list_2020:\n",
    "    ndt1 = norm_year(get_datetime(file1))\n",
    "    for file2 in file_list_2021:\n",
    "        ndt2 = norm_year(get_datetime(file2))\n",
    "        td = abs(ndt1 - ndt2)\n",
    "        if td.total_seconds()/60 < 60:\n",
    "            match_list.append([file1, file2])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "print(f'{len(match_list)} matching scenes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabff2c5-6736-4eae-8bed-06603e4f30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/royalosyin/Overlay-GeoTiff-Raster-with-nodata-On-Interactive-Map/blob/master/scripts/ex2-Overlay%20Raster%20with%20nodata%20on%20Interactive%20Map%20with%20Folium.ipynb\n",
    "\n",
    "vmin = 0\n",
    "vmax = 1\n",
    "\n",
    "#colormap = cm.linear.RdBu_11.scale(vmin, vmax)\n",
    "colormap = cm.linear.magma.scale(vmin, vmax)\n",
    "colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe7ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapvalue2color(value, cmap): \n",
    "    \"\"\"\n",
    "    Map a pixel value of image to a color in the rgba format. \n",
    "    As a special case, nans will be mapped totally transparent.\n",
    "    \n",
    "    Inputs\n",
    "        -- value - pixel value of image, could be np.nan\n",
    "        -- cmap - a linear colormap from branca.colormap.linear\n",
    "    Output\n",
    "        -- a color value in the rgba format (r, g, b, a)    \n",
    "    \"\"\"\n",
    "    if np.isnan(value):\n",
    "        return (1, 0, 0, 0)\n",
    "    else:\n",
    "        return colors.to_rgba(cmap(value), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceed1e2-5ec4-4152-9c34-2e06423c44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dual_map(file1, file2):\n",
    "    with rasterio.open(file1) as src1, rasterio.open(file2) as src2:\n",
    "        data1 = src1.read(1)\n",
    "        data2 = src2.read(1)\n",
    "\n",
    "        meta1 = src1.meta\n",
    "        meta2 = src2.meta\n",
    "\n",
    "        #cmap_data1 = colorize(data1, 9999.0, cmap='viridis')\n",
    "        #cmap_data2 = colorize(data2, 9999.0, cmap='viridis')\n",
    "\n",
    "        #m = folium.plugins.DualMap(location=[src1.bounds[1], src2.bounds[0]], zoom_start=10)\n",
    "        m = folium.plugins.DualMap(location=[y_center, x_center], zoom_start=10, tiles='Esri.WorldImagery')\n",
    "        folium.GeoJson(roi).add_to(m.m1)\n",
    "        folium.raster_layers.ImageOverlay(image=data1, bounds=[[src1.bounds[1], src1.bounds[0]],[src1.bounds[3], src1.bounds[2]]], colormap=lambda value: mapvalue2color(value, colormap), opacity=0.7).add_to(m.m1)\n",
    "        folium.GeoJson(roi).add_to(m.m2)\n",
    "        folium.raster_layers.ImageOverlay(image=data2, bounds=[[src2.bounds[1], src2.bounds[0]],[src2.bounds[3], src2.bounds[2]]], colormap=lambda value: mapvalue2color(value, colormap), opacity=0.7).add_to(m.m2)\n",
    "\n",
    "        folium.LayerControl().add_to(m)\n",
    "\n",
    "        display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d216a6-38bf-4da8-9350-238e30240f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "[m for m in enumerate(match_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7e17b-9721-4eb5-9016-46e60cb466cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=5\n",
    "\n",
    "infile1 = (f'data/{match_list[loc][0]}')\n",
    "infile2 = (f'data/{match_list[loc][1]}')\n",
    "\n",
    "plot_dual_map(infile1, infile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460bdc19-954c-4e7c-807a-a4699f2dcb66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
