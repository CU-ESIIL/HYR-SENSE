{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd57c84-c542-440e-8422-d2a1b68041b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Application of EMIT Data: Agricultural Lands\n",
    "### South Platte and Republican River Basins, CO, USA\n",
    "\n",
    "The South Platte basin is the most populus river basin in Colorado with more than 70% of the state's population living within this region (**[Colorado Water Plan Version 2; South Platte/Metro](https://dnrweblink.state.co.us/cwcbsearch/0/edoc/216720/South_Platte-Metro_BIP_Volume2_2022.pdf)**). This region also has the greatest concentration of irrigated lands in the state.\n",
    "\n",
    "Add introduction here.\n",
    "\n",
    "![Water Figure 14](https://raw.githubusercontent.com/CU-ESIIL/HYR-SENSE/main/images/water_fig14.png)\n",
    "Image source: https://cwcb.colorado.gov/colorado-water-plan/technical-update-to-the-plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e4187-efda-4fb3-9f31-8237234b335c",
   "metadata": {},
   "source": [
    "## Search and Download EMIT Data Products\n",
    "\n",
    "In this notebook, we will use the 'earthaccess' Python package to search and download EMIT scenes which overlap agricultural lands in the South Platte river basin. Using this package, we can search for EMIT scenes using a region of interest and identify data granules which meet certain criteria for analysis (i.e., cloud cover, seasonality, etc). \n",
    "\n",
    "### Step 1. Setup notebook\n",
    "\n",
    "First, we need to import packages and set up some environment variables for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aba902-2bad-4f78-9c33-2f576526bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "\n",
    "import os, time, shutil\n",
    "import folium\n",
    "import earthaccess\n",
    "import warnings\n",
    "import folium.plugins\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from rasterio.plot import show\n",
    "from branca.element import Figure\n",
    "from IPython.display import display\n",
    "from shapely import geometry\n",
    "from skimage import io\n",
    "from datetime import timedelta\n",
    "from shapely.geometry.polygon import orient\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dest = os.path.join(os.path.expanduser(\"~\"),\"HYR-SENSE\",\"data\",\"Agriculture\")\n",
    "# Define some projections\n",
    "albers = 'EPSG:5070' # Albers Equal Area CONUS\n",
    "llwgs84 = 'EPSG:4326' # Geographic - Latitude/Longitude WGS84\n",
    "\n",
    "# Create backup copy of the ortho images on your data store on iplant?\n",
    "create_backup = True # True/False.\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a3c7ba-7548-46f7-a873-591fa4eec41b",
   "metadata": {},
   "source": [
    "#### Transfer project data from the cloud\n",
    "\n",
    "We want to copy over data stored in CyVerse so that we can access files quickly for analysis. To do this, we will use Python \"shutil\" package to copy files from the CyVerse data store to a local, temporary location in the HYR-SENSE GitHub repository. The data we are copying is stored in a shared ESIIL / HYR-SENSE location. We can copy the files just from the \"Agriculture\" module which contains data for this exercise. However, if you want to work with other modules, they can be accessed here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3219d78-c4f1-485e-96de-83b1283be02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copy the data-store to 'local' directory\n",
    "This enables quick access to data files\n",
    "\"\"\"\n",
    "\n",
    "# Identify the location of the HYR-SENSE \"data store\"\n",
    "data_store_path = '/data-store/iplant/home/shared/esiil/HYR_SENSE/data/Agriculture'\n",
    "# Set a destination path (this is a 'local' and temporary path)\n",
    "dest = '/home/jovyan/HYR-SENSE/data/Agriculture/' # in the GitHub repo we cloned\n",
    "if not os.path.exists(dest):\n",
    "    os.mkdir(dest) # create the directory for the copied data, if needed\n",
    "    \n",
    "# Using 'shutil' package, copy all the files over\n",
    "shutil.copytree(data_store_path, dest, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf2a96e-a859-4dc8-a895-1eb1b14c0935",
   "metadata": {},
   "source": [
    "### Step 2. Load Data\n",
    "\n",
    "#### Region of Interest: South Platte & Republican River Basins\n",
    "\n",
    "Let's start by loading the boundary data for the South Platte river basin. This data comes from the Watershed Boundary Dataset (WBD) Hydrologic Unit Codes (HUC). Specifically, we are loading the HUC6 South Platte boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916b352a-e35c-4afc-9ec3-2944a5af95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region of interest\n",
    "roi = os.path.join(dest,'WBD_HUC6_SouthPlatte_Republican.gpkg')\n",
    "#roi_wgs84 = gpd.read_file(roi).to_crs(llwgs84)\n",
    "roi = gpd.read_file(roi).to_crs(albers)\n",
    "print(roi.crs)\n",
    "\n",
    "# Plot the ROI data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "# Use geographic coordinates\n",
    "roi.to_crs(4326).plot(ax=ax, color='white', edgecolor='black')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('South Platte and Republican River Basins (HUC6)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee5930-ad94-4714-9f6c-831b56af3436",
   "metadata": {},
   "source": [
    "### Agricultural land use data\n",
    "\n",
    "In order to get a better picture of where the agricultural land is within the basin, we will load two datasets from the National Agricultural Statistics Service (NASS); 1 - the Cropland Data Layer (CDL) cultivated lands mask, and 2 - the CDL crop type data. To learn more about these data, visit https://croplandcros.scinet.usda.gov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f6f4a1-7e7e-48e6-9218-5a25c13a514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NASS CDL (ca. 2023)\n",
    "cdl = os.path.join(dest,'CDL_2023_CO_SouthPlatte_Republican.tif')\n",
    "cdl = rxr.open_rasterio(cdl, mask=True, cache=False).squeeze().astype(rio.uint8)\n",
    "cdl = cdl.where(cdl != 0, np.nan)  # handle NA values\n",
    "print(cdl)\n",
    "print(cdl.rio.crs) # Check to make sure the projection matches (EPSG:5070)\n",
    "# cdl = cdl.rio.clip(roi.geometry) # clip to the roi for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af324fe-74cb-4328-984b-3c17a4834fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROI data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "roi.plot(ax=ax, color='white', edgecolor='black', linewidth=5.0)\n",
    "cdl.plot(ax=ax, add_colorbar=False, cmap='viridis')  # Customize the colormap as needed\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Cultivated Lands (NASS CDL 2023)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a6c9a-9075-4206-ba3e-70d5ea700ca0",
   "metadata": {},
   "source": [
    "## Search for EMIT Data\n",
    "\n",
    "Using the 'earthaccess' Python package, we can search for EMIT data which overlaps our region of interest. In order to identify data which we can use for analysis, we will also filter for things like season and cloud cover using the metadata for EMIT granules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6ed98-623d-47c1-b93d-9ba67720c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess \n",
    "\n",
    "# Log in to your NASA Earthdata\n",
    "# You only have to do this once in your session (persist=True saves the credentials)\n",
    "earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a458b-7359-46f2-9fc7-1e1afe4a9e84",
   "metadata": {},
   "source": [
    "Now we can use the search functionality of 'earthaccess' to identify data products related to the EMIT mission. This code chunk will return \"short names\" of the data products available. To get a better idea of what each of these products are, you can do a quick search using these short names. For example, to read more about the L2A Estimated Surface Reflectance and Uncertainty and Masks 60-m product you can visit: https://lpdaac.usgs.gov/products/emitl2arflv001/ which pops up when searching the short name \"EMITL2ARFL\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17cc2e-d2e4-49b8-87c8-77aa860bd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the collections\n",
    "Query = earthaccess.collection_query().keyword('emit').provider('LPCLOUD')\n",
    "print(f'Collections found: {Query.hits()}')\n",
    "# Return EMIT specific products\n",
    "collections = Query.fields(['ShortName']).get(Query.hits())\n",
    "# Retrieve Collection Short-names\n",
    "[product['short-name'] for product in [collection.summary() for collection in collections]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc917f6-3e69-4e0c-b97e-b3dd5cd6c7d9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To use a region of interest (ROI) polygon to search for EMIT data, we need to extract the coordinate pairs from our ROI (South Platte) which are then used in the search criteria. The code below will work for a single polygon or for multiple polygons if you wanted to search for data across a variety of ROIs. In this example, we use just one ROI, the South Platte River Basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d32f7-213d-43f6-9476-4c25fa15e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ Extract a list coordinate pairs for ROI ~\n",
    "\n",
    "# First, reproject to WGS84 for coordinates are in lat/long\n",
    "roi = roi.to_crs(epsg=4326)\n",
    "\n",
    "# Extract the bounds\n",
    "coord_list = []\n",
    "for iter, row in roi.iterrows():    \n",
    "    bounds = row['geometry'].bounds\n",
    "    coord_list.append(bounds)\n",
    "print(coord_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bada3a2e-7885-4a78-b06c-ae3cfa4a066a",
   "metadata": {},
   "source": [
    "Now we can run a search for EMIT L2A Reflectance data (short name = 'EMITL2ARFL'). To start, we will search for EMIT data during the **2023 growing season (May-Sept)**. The results from our search is a list of granules which meet the criteria. These granules have associated metadata and we can convert the search results to a data frame to access the granule attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72888404-cdf6-4abb-9e5d-d0f2fad8414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for EMIT data\n",
    "search_results = earthaccess.search_data(\n",
    "    short_name='EMITL2ARFL',\n",
    "    bounding_box=coord_list[0], # we use [0] here because we only have one coordinate pair\n",
    "    temporal=('2023-05-01','2023-09-28'),\n",
    "    count=150\n",
    ")\n",
    "# Extract the metadata json as data frame\n",
    "search_df = pd.json_normalize(search_results)\n",
    "search_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b95bc-e1d1-483c-a0ee-693cc52a112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of granules found: \" + str(len(search_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17da917-33a8-4343-acde-802d2caef2b1",
   "metadata": {},
   "source": [
    "You can see above that we have identified 112 separate granules that meet our current search requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995f5ce-04cb-4be7-8775-f3902536fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of columns from the search results / metadata\n",
    "print(search_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5faf13-f4ac-4c4c-a4aa-11271da4b551",
   "metadata": {},
   "source": [
    "While the list suggests we have 112 granules, we need to apply some additional requirements to ensure the datasets are useable for our application. For example, clouds and cloud cover can impact any analyses looking at the land surface and we often want to \"screen out\" or filter out granules that have substantial cloud cover impacting our region of interest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2fbd71-eb6e-4afe-a342-15d2a35d83f9",
   "metadata": {},
   "source": [
    "## Filter EMIT granules and select \n",
    "\n",
    "In this section we will apply additional data filters to find granules that meet our research requirements. In this case we will select those with low cloud cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d3241-68b9-459b-aef1-1b25842aa365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cloud-free granules\n",
    "print(\"Cloud cover statistics for granules: \\n\")\n",
    "print(search_df['umm.CloudCover'].describe())\n",
    "print(\"~~~~~~~~~~~~~~\")\n",
    "\n",
    "# How many granules have less than 5% cloud cover?\n",
    "no_clouds_n = (search_df['umm.CloudCover'] <= 5).sum()\n",
    "print(f\"Number of granules with less than or equal to 5% cloud cover: {no_clouds_n}\")\n",
    "print(\"~~~~~~~~~~~~~~\")\n",
    "\n",
    "# Filter our search results to just these low cloud granules\n",
    "search_df_nc = search_df[search_df['umm.CloudCover'] <= 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e967d-4237-4e05-aab7-4afc10be3641",
   "metadata": {},
   "source": [
    "After searching for relatively cloud free images, we now see that the total number drops to 34.\n",
    "\n",
    "Now we have a data frame with EMIT granules during the growing season with 0% cloud cover. To further refine this list, lets take a look at the dates of the granules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08df362-8556-484d-a42d-e1842ba0b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the acquisition dates for our no cloud granules\n",
    "print(search_df_nc['umm.TemporalExtent.RangeDateTime.BeginningDateTime'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a05f5df-3bd4-46d0-8db0-d1f17e1ab5b8",
   "metadata": {},
   "source": [
    "It looks like we have some good options for EMIT granules! To get a better idea of the spatial extent of these granules, we can plot their footprints on a map using the metadata from the data search results.\n",
    "\n",
    "Thankfully, the metadata data frame contains information about the spatial extent for each granule which allows us to plot them on an interactive map using 'folium'. We can extract the spatial information and convert that to a geometry with the custom function below \"get_shapely_object\". This come from: XXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc536f1a-f76f-45e1-af4e-00db59818ebf",
   "metadata": {},
   "source": [
    "**In the next step we are defining two new custom functions that will help us evaluate which data granules meet out needs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6702e-f4bc-43f3-98ca-4bf385836306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shapely_object(result:earthaccess.results.DataGranule):\n",
    "    \"\"\"\n",
    "    Retrieve geospatial information from ECOSTRESS granule footprints.\n",
    "    This function allows us to retrieve the geographic coverage for each granule and plot it on a map.\n",
    "    \n",
    "    :param 'result:earthaccess.results.DataGranule': a single data granule from earthaccess data search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get Geometry Keys\n",
    "    geo = result['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']\n",
    "    keys = geo.keys()\n",
    "\n",
    "    if 'BoundingRectangles' in keys:\n",
    "        bounding_rectangle = geo['BoundingRectangles'][0]\n",
    "        # Create bbox tuple\n",
    "        bbox_coords = (bounding_rectangle['WestBoundingCoordinate'],bounding_rectangle['SouthBoundingCoordinate'],\n",
    "                       bounding_rectangle['EastBoundingCoordinate'],bounding_rectangle['NorthBoundingCoordinate'])\n",
    "        # Create shapely geometry from bbox\n",
    "        shape = geometry.box(*bbox_coords, ccw=True)\n",
    "    elif 'GPolygons' in keys:\n",
    "        points = geo['GPolygons'][0]['Boundary']['Points']\n",
    "        # Create shapely geometry from polygons\n",
    "        shape = geometry.Polygon([[p['Longitude'],p['Latitude']] for p in points])\n",
    "    else:\n",
    "         raise ValueError('Provided result does not contain bounding boxes/polygons or is incompatible.')\n",
    "    return(shape)\n",
    "\n",
    "\n",
    "# Convert bounding coordinates to Folium-ready data for mapping\n",
    "def convert_bounds(bbox, invert_y=False):\n",
    "    \"\"\"\n",
    "    Helper method for changing bounding box representation to leaflet notation\n",
    "    Leaflet interactive maps require a specific format for coordinates, this function sets that up for a given bounding box.\n",
    "\n",
    "    ``(lon1, lat1, lon2, lat2) -> ((lat1, lon1), (lat2, lon2))``\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    if invert_y:\n",
    "        y1, y2 = y2, y1\n",
    "    return ((y1, x1), (y2, x2))\n",
    "\n",
    "print(\"Ready to use function(s)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded58ad7-fe5b-435d-86a4-b80d81118a55",
   "metadata": {},
   "source": [
    "You can see above that the functions were successfully defined and now we can use them in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e5a97-f69e-47cc-9bbe-9e7c97c85757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the bounding information\n",
    "\n",
    "# Create shapely polygons for result\n",
    "geometries = [get_shapely_object(search_results[index]) for index in search_df_nc.index.to_list()]\n",
    "# Convert to GeoDataframe\n",
    "results_gdf = gpd.GeoDataFrame(search_df_nc, geometry=geometries, crs=\"EPSG:4326\")\n",
    "# Ensure 'start_datetime' and other relevant datetime columns are strings\n",
    "results_gdf['start_datetime'] = results_gdf['umm.TemporalExtent.RangeDateTime.BeginningDateTime'].astype(str)\n",
    "results_gdf = results_gdf[['meta.native-id','start_datetime','geometry']]\n",
    "\n",
    "# Create the interactive map using folium\n",
    "fig = Figure(width=\"750px\", height=\"375px\")\n",
    "map1 = folium.Map(tiles='https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}', attr='Google')\n",
    "fig.add_child(map1)\n",
    "\n",
    "# Plot Region of Interest\n",
    "roi.drop(columns=['LOADDATE']).explore(\n",
    "    popup=False,\n",
    "    style_kwds=dict(fillOpacity=0.1, width=2),\n",
    "    name=\"South Platte River Basin\",\n",
    "    m=map1\n",
    ")\n",
    "\n",
    "results_gdf.explore(\n",
    "    \"meta.native-id\",\n",
    "    categorical=True,\n",
    "    tooltip=[\n",
    "        \"meta.native-id\",\n",
    "        \"start_datetime\",\n",
    "    ],\n",
    "    popup=True,\n",
    "    style_kwds=dict(fillOpacity=0.1, width=2),\n",
    "    name=\"EMIT\",\n",
    "    m=map1,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "map1.fit_bounds(bounds=convert_bounds(results_gdf.unary_union.bounds))\n",
    "map1.add_child(folium.LayerControl())\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b765788a-4a72-4b74-9b6e-b817c3f13ddf",
   "metadata": {},
   "source": [
    "Using the interactive map above, you can now review the remaining granules meeting our research and location requirements. Using the map you can scroll around, hover over specific granule outlines to see details, or click on specific image outlines to get the details.  You can also zoom in and out to review areas with multiple overlapping granules from different dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c232e-4745-4e8b-9f82-dabee4ef7d40",
   "metadata": {},
   "source": [
    "## Select and download EMIT granules to use in the rest of the tutorial\n",
    "\n",
    "Based on the results above we will select four granules from 2023-07-29 that represent a small stip of images covering a large fraction of the agricultural landscapoe in the Southwestern/Northeastern portion of Nebraska and Colorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3053d-10ca-4508-9bc4-a19bdc542aa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets define the 4 granules from 2023-07-29 to download for the tutorial\n",
    "selected_granules = ['EMIT_L2A_RFL_001_20230729T205653_2321014_021',\n",
    "                     'EMIT_L2A_RFL_001_20230729T205642_2321014_020',\n",
    "                     'EMIT_L2A_RFL_001_20230729T205630_2321014_019',\n",
    "                     'EMIT_L2A_RFL_001_20230729T205618_2321014_018']\n",
    "\n",
    "# Filter our metadata, plot the selected granules\n",
    "granules = search_df_nc[search_df_nc['meta.native-id'].isin(selected_granules)]\n",
    "granules_gdf = results_gdf[results_gdf['meta.native-id'].isin(selected_granules)]\n",
    "\n",
    "# Create the interactive map using folium\n",
    "fig = Figure(width=\"750px\", height=\"375px\")\n",
    "map1 = folium.Map(tiles='https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}', attr='Google')\n",
    "fig.add_child(map1)\n",
    "\n",
    "# Plot Region of Interest\n",
    "roi.drop(columns=['LOADDATE']).explore(\n",
    "    popup=False,\n",
    "    style_kwds=dict(fillOpacity=0.1, width=2),\n",
    "    name=\"South Platte River Basin\",\n",
    "    m=map1\n",
    ")\n",
    "\n",
    "granules_gdf.explore(\n",
    "    \"meta.native-id\",\n",
    "    categorical=True,\n",
    "    tooltip=[\n",
    "        \"meta.native-id\",\n",
    "        \"start_datetime\",\n",
    "    ],\n",
    "    popup=True,\n",
    "    style_kwds=dict(fillOpacity=0.1, width=2),\n",
    "    name=\"EMIT\",\n",
    "    m=map1,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "map1.fit_bounds(bounds=convert_bounds(granules_gdf.unary_union.bounds))\n",
    "map1.add_child(folium.LayerControl())\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c79e7-f757-464f-ac73-05f65327568c",
   "metadata": {},
   "source": [
    "Note: You can see in the map above the specific granules we have selected to download and work with in the tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103c20b-df79-4116-be4c-1db2b0b59705",
   "metadata": {},
   "source": [
    "### Now lets download the four selected \n",
    "\n",
    "We will use a simple loop to download the granules from EarthData below and provide us a verbose output showing the progress of the data downloading.  The first time you run this you will note that a new \"EMIT\" folder is created in \"HYR-SENSE/data/Agriculture/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4404ca-bd64-4e55-a6e6-c6457982d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the scenes and store in your \"local\" working/scratch folder for faster I/O and data access in the remaining tutorials\n",
    "# local relates to the path /home/jovyan/HYR-SENSE/data/\n",
    "\n",
    "# Retrieve the download URL\n",
    "granule_ids = [f\"{granule}/{granule}.nc\" for granule in granules['umm.GranuleUR']]\n",
    "\n",
    "# Get Https Session using Earthdata Login Info\n",
    "fs = earthaccess.get_fsspec_https_session()\n",
    "\n",
    "# Base download URL\n",
    "base_url = 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001'\n",
    "\n",
    "# Define local storage location on CyVerse - default is HYR-SENSE/data/emit\n",
    "loc_file_path = os.path.join('/home/jovyan/HYR-SENSE/data/Agriculture/emit/')\n",
    "if not os.path.exists(loc_file_path):\n",
    "    os.mkdir(loc_file_path)\n",
    "\n",
    "# Download the data granules\n",
    "t0 = time.time()\n",
    "\n",
    "for granule_id in granule_ids:\n",
    "    print(granule_id)\n",
    "    print(\"Granule ID: \" + granule_id.split('/')[1])\n",
    "    granule_asset_id = granule_id.split('/')[1]\n",
    "    out_path = loc_file_path + f'{granule_asset_id}'\n",
    "\n",
    "    # Download the Granule Asset if it doesn't exist\n",
    "    url = os.path.join(base_url,granule_id)\n",
    "    if not os.path.isfile(out_path):\n",
    "        fs.download(url, out_path)\n",
    "\n",
    "print('Total time:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738b281d-d480-44e4-b302-6e09360c8d73",
   "metadata": {},
   "source": [
    "Let's also save the geospatial footprints for our selected tiles. This will be useful in the preceding notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8121a3-1ca0-4e10-bf27-18cbcad283b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fpath = os.path.join(dest,'emit_granule_footprints.gpkg')\n",
    "granules_gdf.to_file(out_fpath)\n",
    "print(f\"EMIT footprints saved to {out_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da3e72-107d-4ee1-aed4-b18cd1fd82c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### OPTIONAL: If you only want to download a single granule, we can select the image centered on Yuma, Colorado from July 29th 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da725f3-93a8-4fbf-92ef-d88137af3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_granules = ['EMIT_L2A_RFL_001_20230729T205630_2321014_019']\n",
    "\n",
    "# Filter our metadata, plot the selected granules\n",
    "granules = search_df_nc[search_df_nc['meta.native-id'].isin(selected_granules)]\n",
    "granules_gdf = results_gdf[results_gdf['meta.native-id'].isin(selected_granules)]\n",
    "\n",
    "# Create the interactive map using folium\n",
    "fig = Figure(width=\"750px\", height=\"375px\")\n",
    "map1 = folium.Map(tiles='https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}', attr='Google')\n",
    "fig.add_child(map1)\n",
    "\n",
    "# Plot Region of Interest\n",
    "roi.drop(columns=['LOADDATE']).explore(\n",
    "    popup=False,\n",
    "    style_kwds=dict(fillOpacity=0.1, width=2),\n",
    "    name=\"South Platte River Basin\",\n",
    "    m=map1\n",
    ")\n",
    "\n",
    "granules_gdf.explore(\n",
    "    \"meta.native-id\",\n",
    "    categorical=True,\n",
    "    tooltip=[\n",
    "        \"meta.native-id\",\n",
    "        \"start_datetime\",\n",
    "    ],\n",
    "    popup=True,\n",
    "    style_kwds=dict(fillOpacity=0.1, width=2),\n",
    "    name=\"EMIT\",\n",
    "    m=map1,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "map1.fit_bounds(bounds=convert_bounds(granules_gdf.unary_union.bounds))\n",
    "map1.add_child(folium.LayerControl())\n",
    "display(fig)\n",
    "\n",
    "print(granules_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b78f1b-6afe-46cf-9706-eff21f58143c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Download the EMIT_L2A_RFL_001_20230729T205630_2321014_019\n",
    "\n",
    "Will only download if the file doesnt already exist.  If it already exists, it will skip downloading and print back the granule ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409e153-8f82-4bec-a65c-0e7e6f6325c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download the scenes, store in working/scratch folder for faster I/O and data access in the remaining tutorials\n",
    "# Retrieve the download URL\n",
    "granule_ids = [f\"{granule}/{granule}.nc\" for granule in granules['umm.GranuleUR']]\n",
    "\n",
    "# Get Https Session using Earthdata Login Info\n",
    "fs = earthaccess.get_fsspec_https_session()\n",
    "\n",
    "# Base download URL\n",
    "base_url = 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001'\n",
    "\n",
    "# Define local storage location on CyVerse - default is HYR-SENSE/data/Agriculture/emit\n",
    "loc_file_path = os.path.join('/home/jovyan/HYR-SENSE/data/Agriculture/emit/')\n",
    "if not os.path.exists(loc_file_path):\n",
    "    os.mkdir(loc_file_path)\n",
    "\n",
    "# Download the data granules\n",
    "t0 = time.time()\n",
    "\n",
    "for granule_id in granule_ids:\n",
    "    print(granule_id)\n",
    "    print(\"Granule ID: \" + granule_id.split('/')[1])\n",
    "    granule_asset_id = granule_id.split('/')[1]\n",
    "    out_path = loc_file_path + f'{granule_asset_id}'\n",
    "    print(out_path)\n",
    "    # Download the Granule Asset if it doesn't exist\n",
    "    url = os.path.join(base_url,granule_id)\n",
    "    if not os.path.isfile(out_path):\n",
    "        fs.download(url, out_path)\n",
    "    if os.path.isfile(out_path):\n",
    "        print(\"*** Already downloaded ***\")\n",
    "        print(\" \")\n",
    "\n",
    "print('Total time:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f58203-1f6f-447c-949d-6106dde5ae82",
   "metadata": {},
   "source": [
    "## OPTIONAL: Create a copy of the downloaded data in the workshop storage\n",
    "\n",
    "Let's create a backup copy from what is in the current scratch folder for later use and to avoid having to download again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e08f4-414a-4847-a4a0-9e192e42084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Copy data to CyVerse data store for download\n",
    "if create_backup:\n",
    "    user_name = os.environ.get(\"IPLANT_USER\")\n",
    "    print(\"*** Iplant username: \" + user_name)\n",
    "    src_dir = os.path.join('/home/jovyan/HYR-SENSE/data/Agriculture/emit/')\n",
    "    dest_dir = os.path.join('/data-store/iplant/home/',user_name,'emit')\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"**** Copy complete!! ****\")\n",
    "else:\n",
    "    print(\"\")\n",
    "    print(\"*** Skipping backup of ortho images ***\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae81a22-7524-420f-a46c-1519bb44ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dest_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyr-sense",
   "language": "python",
   "name": "hyr-sense"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
