{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To: Convert EMIT .nc to .envi\n",
    "\n",
    "There are currently 2 similar methods to convert the EMIT netCDF4 files to `.envi` format. Note these only support L1B Radiance, L1B Obs, L2A Reflectance, L2A Reflectance Uncertainty, or L2A Mask to .envi. They do not yet support the L2B Mineral or L2B Mineral Uncertainty products.\n",
    "1. The `write_envi` function in EMIT tools. This function is still being developed but will currently:\n",
    "  - Write a GLT output to use for orthocorrection later \n",
    "  - Functions from `emit_tools` can be used beforehand to orthorectify if so desired\n",
    "2. The `reformat.py` script available in the [emit-sds/emit-utils](https://github.com/emit-sds/emit-utils) repository can be used to convert EMIT netCDF files (as delivered to the LP DAAC) to ENVI files. This script also can apply the included GLT to orthorectify the image if desired.\n",
    "\n",
    "This jupyter notebook walks through how to use both methods to provide users with programmatic routes to accomplish their EMIT reformatting workflows.\n",
    "\n",
    "**Requirements:**\n",
    "+ A NASA [Earthdata Login](https://urs.earthdata.nasa.gov/) account is required to download EMIT data   \n",
    "+ Selected the `emit_tutorials` environment as the kernel for this notebook.\n",
    "  + For instructions on setting up the environment, follow the the `setup_instructions.md` included in the `/setup/` folder of the repository.  \n",
    "\n",
    "**Learning Objectives**\n",
    "+ How to use the `write_envi` function from `emit_tools` module to convert an EMIT netCDF4 to a `.envi` file.\n",
    "+ How to use the `reformat.py` function from the `emit-utils` repository to convert an EMIT netCDF4 to a `.envi` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import earthaccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate using Earthdata Login and Download the required Granules\n",
    "\n",
    "Login to your NASA Earthdata account and create a `.netrc` file using the `login` function from the `earthaccess` library. If you do not have an Earthdata Account, you can create one [here](https://urs.earthdata.nasa.gov/home). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<earthaccess.auth.Auth at 0x7fe57e16d7b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook we will download the files necessary using `earthaccess`. You can also access the data in place or stream it, but this can slow due to the file sizes. Provide a URL for an EMIT L2A Reflectance granule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an HTTPS Session using your earthdata login, set a local path to save the file, and download the granule asset - This may take a while, the reflectance file is approximately 1.8 GB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Https Session using Earthdata Login Info\n",
    "fs = earthaccess.get_fsspec_https_session()\n",
    "# Retrieve granule asset ID from URL (to maintain existing naming convention)\n",
    "granule_asset_id = url.split('/')[-1]\n",
    "# Define Local Filepath\n",
    "fp = f'../../data/emit/{granule_asset_id}'\n",
    "# Download the Granule Asset if it doesn't exist\n",
    "if not os.path.isfile(fp):\n",
    "    fs.download(url, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create an output folder where we will save the `.envi` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = '../../data/emit/ag/envi' \n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Using `write_envi` from the `emit_tools` module.\n",
    "\n",
    "Import the necessary packages for this method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../tools/emit/python/modules/')\n",
    "import emit_tools as et"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the granule using the `emit_xarray` function. We can orthorectify here if so desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emit_tools as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unrecognized engine h5netcdf must be one of: ['netcdf4', 'scipy', 'pydap', 'rasterio', 'store', 'zarr']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43met\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memit_xarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mortho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m ds\n",
      "File \u001b[0;32m~/HYR-SENSE/notebooks/agriculture/../../tools/emit/python/modules/emit_tools.py:61\u001b[0m, in \u001b[0;36memit_xarray\u001b[0;34m(filepath, ortho, qmask, unpacked_bmask)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Read in Data as Xarray Datasets\u001b[39;00m\n\u001b[1;32m     59\u001b[0m engine, wvl_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5netcdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m loc \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(filepath, engine\u001b[38;5;241m=\u001b[39mengine, group\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Check if mineral dataset and read in groups (only ds/loc for minunc)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/hyr-sense/lib/python3.10/site-packages/xarray/backends/api.py:558\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    556\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 558\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    561\u001b[0m     decode_cf,\n\u001b[1;32m    562\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    569\u001b[0m )\n\u001b[1;32m    571\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/envs/hyr-sense/lib/python3.10/site-packages/xarray/backends/plugins.py:205\u001b[0m, in \u001b[0;36mget_backend\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m    203\u001b[0m     engines \u001b[38;5;241m=\u001b[39m list_engines()\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m engines:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be one of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(engines)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m         )\n\u001b[1;32m    208\u001b[0m     backend \u001b[38;5;241m=\u001b[39m engines[engine]\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(engine, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(engine, BackendEntrypoint):\n",
      "\u001b[0;31mValueError\u001b[0m: unrecognized engine h5netcdf must be one of: ['netcdf4', 'scipy', 'pydap', 'rasterio', 'store', 'zarr']"
     ]
    }
   ],
   "source": [
    "ds = et.emit_xarray(fp, ortho=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write the dataset as an `.envi` output. If we chose not to orthorectify, you can include a `glt` file to orthorectify later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.write_envi(ds, outpath, overwrite=False, extension='.img', interleave='BIL', glt_file=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Using reformat.py from emit-utils\n",
    "\n",
    "### 2.1 Clone and Install emit-utils\n",
    "\n",
    "Clone the [emit-utils](https://github.com/emit-sds/emit-utils) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '../emit_utils'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/emit-sds/emit-utils.git ../emit_utils/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will copy the `emit-utils` repository to a folder within this repository. \n",
    "\n",
    "After you have copied it, use `pip` package manager to install the directory as a package to ensure you have all of the dependencies and be used in the command line. \n",
    "\n",
    "> **This requires that some dependencies already be installed to work properly on Windows. If you have created the Python environment described in the [setup instructions](../../setup/setup_instructions.md) it should work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/ebolch/repos/EMIT-Data-Resources/python/emit_utils\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: gdal>=2.0 in c:\\users\\ebolch\\appdata\\local\\mambaforge\\envs\\emit_tutorials_311\\lib\\site-packages (from emit-utils==1.2.3) (3.6.4)\n",
      "Requirement already satisfied: spectral>=0.21 in c:\\users\\ebolch\\appdata\\local\\mambaforge\\envs\\emit_tutorials_311\\lib\\site-packages (from emit-utils==1.2.3) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.19.2 in c:\\users\\ebolch\\appdata\\local\\mambaforge\\envs\\emit_tutorials_311\\lib\\site-packages (from emit-utils==1.2.3) (1.24.4)\n",
      "Requirement already satisfied: netcdf4>=1.5.8 in c:\\users\\ebolch\\appdata\\local\\mambaforge\\envs\\emit_tutorials_311\\lib\\site-packages (from emit-utils==1.2.3) (1.6.4)\n",
      "Collecting argparse>=1.0 (from emit-utils==1.2.3)\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: cftime in c:\\users\\ebolch\\appdata\\local\\mambaforge\\envs\\emit_tutorials_311\\lib\\site-packages (from netcdf4>=1.5.8->emit-utils==1.2.3) (1.6.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\ebolch\\appdata\\local\\mambaforge\\envs\\emit_tutorials_311\\lib\\site-packages (from netcdf4>=1.5.8->emit-utils==1.2.3) (2023.5.7)\n",
      "Installing collected packages: argparse, emit-utils\n",
      "  Running setup.py develop for emit-utils\n",
      "Successfully installed argparse-1.4.0 emit-utils-1.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --editable ../emit_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully installing `emit-utils`, you can use the scripts contained within as part of your workflows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Executing the Reformat Script\n",
    "\n",
    "Before calling the `reformat.py` script, make sure you have an output directory for the `.envi` files that will be produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "outpath = '../../data/envi' \n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the `reformat.py` script contained in the emit-utils repository. When executing this script, provide the path to the `.nc` file, followed by the directory to place the `.envi` files in. If you wish to apply the GLT or orthorectify, include `--orthorectify` as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ../emit_utils/emit_utils/reformat.py ../../data/EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc ../../data/envi/ --orthorectify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will orthorectify the image, create an ENVI header, and save it in `.envi` format inside the `../data/envi` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact Info:  \n",
    "\n",
    "Email: LPDAAC@usgs.gov  \n",
    "Voice: +1-866-573-3222  \n",
    "Organization: Land Processes Distributed Active Archive Center (LP DAAC)¹  \n",
    "Website: <https://lpdaac.usgs.gov/>  \n",
    "Date last modified: 07-06-2023  \n",
    "\n",
    "¹Work performed under USGS contract G15PD00467 for NASA contract NNG14HH33I.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyr-sense",
   "language": "python",
   "name": "hyr-sense"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee32eb811eece122811842209709e899a392a6a8deb39746eb88e988164e27f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
